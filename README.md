# DeltaQuanta

> **Data Engineering Excellence Starts Here**  
> A fully containerized Lakehouse pipeline with Delta Lake, Spark optimizations, and Prefect orchestration.

---

## ğŸ·ï¸ Key Features

- **Modern Lakehouse Architecture**  
  - Delta Lake storage with ACID transactions & timeâ€‘travel  
  - Spark SQL & DataFrame optimizations (caching, partition pruning, AQE)
- **Data Lake & Partitioning Design**  
  - Separate Delta tables per factor type  
  - Partitioned by `symbol` and date fields for each table  
  - Z-Order on `symbol` to speed up point lookups
- **Endâ€‘toâ€‘End Docker Packaging**  
  - Oneâ€‘step `docker compose up --build`  
  - Services: Prefect Orion, Spark ETL, MinIO (S3), Streamlit app  
- **Automated Workflow & CI/CD**  
  - Prefect 2.x flows with daily scheduling, alerts  
  - GitHub Actions on push to `main`

---

## âš™ï¸ Partitioned Table Structure

Below is the directory layout under `data/lake/`, showing partitions for each Delta table:

```
data/lake/  
â”œâ”€â”€ PriceFactors/ # Price related features  
â”‚ â”œâ”€â”€ symbol=AAPL/ # Partition by symbol  
â”‚ â”‚ â”œâ”€â”€ trade_date=2025-07-01/part-...snappy.parquet  
â”‚ â”‚ â””â”€â”€ trade_date=2025-07-02/...  
â”‚ â””â”€â”€ symbol=TSLA/  
â”œâ”€â”€ VolumeFactors/ # Volume related features  
â”‚ â””â”€â”€ symbol=AAPL/  
â”‚ â””â”€â”€ trade_date=2025-07-01/...  
â”œâ”€â”€ ImpactFactors/ # Impact & liquidity features  
â”‚ â””â”€â”€ symbol=AAPL/  
â”‚ â””â”€â”€ trade_date=2025-07-01/...  
â””â”€â”€ Fundamentals/ # Fundamental metrics   
â””â”€â”€ symbol=AAPL/   
â”œâ”€â”€ report_date=2025-07-27/part-...parquet   
â””â”€â”€ report_date=2025-04-30/...
```

- **PriceFactors** partition keys: `symbol`, `trade_date`
- **VolumeFactors** partition keys: `symbol`, `trade_date`
- **ImpactFactors** partition keys: `symbol`, `trade_date`
- **Fundamentals** partition keys: `symbol`, `report_date`

Partitioning by date fields ensures predicate pushdown and efficient scans.

---


## âš™ï¸ Architecture Overview

```text
[ Finnhub API ]
       â†“
 [ /ingestion/fetch_stock_data.py ]
       â†“
   Raw JSON â†’ data/lake/stocks_delta
       â†“
 [ etl/spark_job.py â†’ transform_indicators ]
       â†“
 Enriched Delta â†’ data/lake/stocks_enriched
       â†“
 [ workflows/prefect_pipeline.py ]
       â†“
 Scheduled daily, alerts on failure
       â†“
   Docker Compose & GitHub Actions
```

---

## ğŸ“¦ Quick Start

```bash
# 1. Clone the repo
git clone https://github.com/cl17189/quantlake.git
cd quantlake

# 2. Configure environment
cp .env.sample .env  # then edit the file
# Fill in:
# FINNHUB_API_KEY=your_token
# AWS_ACCESS_KEY_ID=minio
# AWS_SECRET_ACCESS_KEY=minio123
# MINIO_ENDPOINT=http://minio:9000

# 3. Build and launch
cd docker
docker compose up --build
```

---

## ğŸ“Š Computed Indicators

| Category        | Indicator                   |
| --------------- | --------------------------- |
| **Price Action**| `price_change_pct`, `ma_5`, `ma_20`, `price_volatility_7d`, `jump_risk_index` |
| **Volume Flow** | `volume_spike_ratio`, `turnover_ratio`              |
| **Impact & Liquidity** | `price_impact_factor`, `abnormal_volume_index`   |
| **Fundamentals**| `pe_ratio`, `eps`, `revenue`       |
| **(Optional)**  | `news_sentiment_score`             |

---

## ğŸ”§ Tech Stack

![Tech Stack](pic/tech_stack.jpg)

- **Python 3.10** Â· **PySpark** Â· **delta-spark**  
- **Prefect 2.x** Â· **Docker & Docker Compose**  
- **MinIO** (S3â€‘compatible) Â· **GitHub Actions**

---


## ğŸ“¬ License & Contact

- Released under the MIT License  
